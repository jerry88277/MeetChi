# MVP 開發任務文件 (Development Tasks)

本文件將 MVP 的開發工作拆分為多個 Sprint，並以 CheckList 形式呈現，以便追蹤開發與測試狀態。

---

## 部署階段一：本機開發與驗證 - ASR 準確率與即時性驗證 (Local-Only Deployment - ASR Accuracy and Real-time Verification)

### Sprint 0: 環境搭建 (簡化版)
- [x] **開發任務 (全員)**: 安裝 Node.js, Python (`conda` 或 `venv`) 等本地開發環境。
- [x] **開發任務 (AI)**: 準備一個 Python 腳本 (`transcribe.py`)，能夠直接從 Hugging Face 加載並運行 `Taiwan-Tongues-ASR-CE` 模型，並提供一個可供呼叫的函式 (e.g., `def get_transcription(audio_chunk):`)。**參考建議：** 檢視 `apps/backend/scripts/exec_whisperx_task_v1.2.py`，提取其模型載入、繁中轉換及斷詞等核心邏輯。
- [x] **開發任務 (全端)**: 建立 FastAPI 專案，並設定好基本的資料庫連線 (本地 Postgres 或 SQLite)。
- [x] **測試任務**: AI 工程師需能成功執行 `transcribe.py` 腳本，並傳入音訊檔案，確認能得到轉錄結果。

### Sprint 1: 核心轉錄管線 (本地直接呼叫)
- [x] **開發任務 (全端)**: 實作前端音訊捕獲與 VAD 功能，並建立到後端 FastAPI 的 WebSocket 連線，能持續發送音訊流。
- [x] **開發任務 (AI/全端)**: 將 `transcribe.py` 中的轉錄函式整合進 FastAPI 應用程式中。FastAPI 在收到 WebSocket 的音訊流時，**直接在同一個服務進程中呼叫該函式**進行轉錄。
- [x] **測試任務**: 啟動 FastAPI 後端與 Next.js 前端。播放一段清晰的中文 YouTube 音訊，確認後端 FastAPI 日誌能**實時、高準確率**地打印出由**轉錄函式**回傳的「原始」中文逐字稿。測試不同口音與語速的音訊，記錄其**轉錄準確率**。
    *   **備註**: 已驗證後端轉錄功能與 WebSocket 通訊正常。前端因本地麥克風硬體/驅動問題無法擷取聲音 (Windows 系統層級無訊號)。已透過後端「模擬模式」成功驗證從音訊檔讀取並即時推送到前端顯示逐字稿的完整流程。

### Sprint 2: 不中斷轉錄與 LLM 潤飾
- [x] **開發任務 (AI)**: 建立一個 **Flask API** 服務來提供 LLM 潤飾功能。該服務需從 Hugging Face 加載並運行聯發科的 **Breeze2 3B** 模型，並設計高效的潤飾與翻譯 Prompt。
- [x] **開發任務 (全端)**: 在閘道中整合潤飾服務，並實作「先顯示原始稿，再非同步更新潤飾稿」的訊息機制。
- [x] **開發任務 (全端)**: 在前端實作接收更新訊息並替換文字的邏輯。
- [x] **測試任務**: 啟動所有服務，播放一段長度超過 5 分鐘、語速變化的中英夾雜 YouTube 影片。確認：1. 轉錄過程**不中斷，延遲在 3 秒內**。 2. 前端介面能看到原始文字被**高準確度潤飾**後文字替換的過程。 3. 停止錄製後，轉錄停止。

### Sprint 3: 雙語功能、UI 與核心優化
- [x] **優化任務 (AI/全端)**: 研究並改善音訊切分策略（如：滑動窗口 Overlapping 或 VAD 觸發機制），解決固定時間切分造成的語句破碎問題，以提升下游 LLM 翻譯品質。
    *   **備註**: 即時轉錄階段的 VAD (Voice Activity Detection) 僅專注於區分語音與非語音，不具備區分不同講者的能力。講者分離 (Speaker Diarization) 為更高層次的技術，通常會導致顯著的處理延遲，因此目前不納入即時轉錄的範疇。講者分離功能將規劃為會議紀錄後處理或未來階段的功能。
- [x] **優化任務 (AI)**: 微調 LLM System Prompt，減少過度改寫與客套話，並降低因輸入破碎產生的幻覺。
- [x] **開發任務 (AI)**: 為 LLM 服務增加翻譯功能，使其能一次性回傳潤飾後的原文與譯文。
- [x] **開發任務 (全端)**: 完成前端 UI，包括「開始/停止」按鈕、「單語/雙語模式」切換按鈕、「語言互換」按鈕。
- [x] **開發任務 (全端)**: 根據「功能設計文件」，完成前端的狀態管理與渲染邏輯。
- [x] **測試任務**: 完整測試所有 UI 功能：1. 開始/停止按鈕功能正常。 2. **實時測試**「單語字幕」與「雙語字幕」模式切換，確認**切換後的文字內容與排版正確**。 3. **實時測試**「語言互換」按鈕，確認**內容互換正確且 UI 無閃爍**。 4. 確認 UI 狀態顯示正確（如 "正在聆聽...", "連線中斷"）。 5. 確認整體 UI/UX 流暢且對應 ASR/LLM 回應快速。

---

## 優化階段：即時轉錄品質對齊 (Quality Alignment)

### Sprint 4: 架構優化與幻覺抑制
- [x] **優化任務 (後端/AI)**: **Smart Buffering (智慧緩衝)** - 在 `main.py` 實作滑動窗口 (Rolling Buffer) 機制。將上一片段的最後 0.5~1.0 秒音訊與當前片段合併送入 Whisper，確保語音邊界完整，解決「斷詞」與語意不連貫問題。
- [x] **優化任務 (後端/AI)**: **Calm VAD (VAD 鎮靜劑)** - 修改 `vad.py`，將 `min_silence_duration` 提升至 1.0s，並增加 `min_speech_duration` 過濾，減少因噪音觸發的破碎切分。
- [x] **優化任務 (後端/AI)**: **Hallucination Firewall (幻覺防火牆)** - 在 `transcribe_sprint0.py` 實作多層次過濾：
    1.  **LogProb 檢查**: 丟棄 `no_speech_prob` 過高的片段。
    2.  **黑名單過濾**: 針對 Whisper 常見幻覺詞 (如 "謝謝觀看", "字幕提供") 建立過濾清單。
    3.  **Breeze-8B 上下文感知**: 利用 LLM 進行二次確認，若翻譯結果與上文極度不連貫則回退。
- [x] **測試任務**: 使用 **前端系統音訊 (System Audio)** 進行實測，確認：
    1.  即時轉錄內容與離線轉錄的**語意一致性**大幅提升。
    2.  靜音時不再出現 "Thank you" 或重複語句。
    3.  延遲控制在合理範圍 (< 5s)。

---

## 擴充階段：桌面體驗與進階控制 (Desktop Experience & Advanced Control)

### Sprint 4.5: 桌面應用與進階設定
- [x] **開發任務 (前端)**: **Initial Prompt 設定介面** - 在網頁版新增設定按鈕，允許使用者輸入並儲存自定義的 `initial_prompt` (如會議主題、專有名詞)，並透過 WebSocket 傳送給後端。
- [x] **開發任務 (桌面端)**: **Electron 專案初始化** - 建立 `apps/desktop`，整合現有 Next.js 前端。
- [x] **開發任務 (桌面端)**: **視窗控制與樣式** - 實作 Electron 視窗的「永遠置頂 (Always on Top)」、「半透明背景」與「無邊框拖曳 (Frameless Drag)」功能。
- [x] **開發任務 (桌面端)**: **字體大小與透明度控制** - 在前端新增調整 UI 並透過 IPC 控制 Electron 視窗。
- [x] **開發任務 (前端/Electron)**: **系統音訊擷取** - 使用 `desktopCapturer` 解決 Electron 下的系統音訊權限問題。
- [ ] **測試任務**: 驗證桌面應用的系統音訊抓取能力，以及 `initial_prompt` 對轉錄準確度的影響。

### Sprint 4.6: 沉浸式 UI 重構 (Immersive UI Refactor) - New!
- [x] **開發任務 (前端)**: **設定面板分離** - 建立 `SettingsModal` 元件，將音訊來源、語言、Prompt、外觀設定全部移入此模態對話框。
- [x] **開發任務 (前端)**: **主視窗重構** - 移除主畫面的控制項，僅保留字幕顯示區與隱藏式 Title Bar。
- [x] **開發任務 (前端)**: **Title Bar 互動** - 實作「滑鼠移入顯示 / 移出隱藏」邏輯，並在 Title Bar 上整合錄製、設定與視窗控制按鈕。
- [x] **開發任務 (前端)**: **字幕區點擊錄製** - 實作點擊字幕區域切換錄製/暫停的功能，並加入視覺回饋 (如 Play/Pause 圖示)。
- [x] **開發任務 (前端)**: **顯示行數設定** - 在設定面板新增「最大顯示行數」選項，並透過 CSS/JS 限制字幕區域高度。

---

## 部署階段二：類伺服器平台部署 (Staging Deployment)

### Sprint 5: 遷移至 Render/Cloudflare/Neon
- [ ] **開發任務 (全端/GCP)**: 將 Next.js 前端專案部署到 **Cloudflare Pages**。
- [ ] **開發任務 (全端/GCP)**: 將 FastAPI 閘道與 LLM 潤飾服務容器化，並部署到 **Render**。
- [ ] **開發任務 (全端/GCP)**: 將資料庫 Schema 與連線遷移至 **Neon** 雲端實例。
- [ ] **挑戰與任務 (AI/GCP)**: Render 不提供 GPU 且資源有限。此階段 ASR/LLM 服務有兩個選項：
    1.  **選項 A (建議)**: 暫時切換為使用第三方 ASR API（如 Deepgram/AssemblyAI）以驗證雲端管線。
    2.  **選項 B**: 在本地保留 ASR 服務，並使用 ngrok 等工具建立通道供 Render 呼叫（僅供測試）。
- [ ] **測試任務**: 使用公網 URL 訪問 Cloudflare Pages 前端，完整執行一次 Sprint 3 的測試案例，確認所有功能在 Staging 環境下正常運作。

---

## 部署階段三：GCP 生產環境部署 (Production Deployment)

### Sprint 6: 遷移至 GCP
- [ ] **開發任務 (GCP)**: 在 **GKE** 上建立 GPU 節點池，並使用 Terraform 或 `gcloud` 腳本將容器化的 `Taiwan-Tongues-ASR-CE` 部署上去。
- [ ] **開發任務 (GCP)**: 將 Render 上的 FastAPI 與 LLM 服務遷移至 **Cloud Run** 或 GKE。
- [ ] **開發任務 (全端)**: 修改前端設定，將其 API 與 WebSocket 指向 GCP 的負載均衡器。
- [ ] **開發任務 (資安)**: 配置 GCP 的防火牆、IAM 與 Secret Manager，確保生產環境安全。
- [ ] **測試任務**: 使用生產環境 URL，再次完整執行一次 Sprint 3 的測試案例。
- [ ] **壓力測試任務 (GCP/全端)**: 模擬 10 個使用者同時連線進行轉錄，監控 GKE 的自動擴展（Auto-scaling）與 Cloud Run 的並發實例，確保系統穩定。