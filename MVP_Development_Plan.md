# 會議 AI 助理 MVP 開發藍圖 (V2)

## 第一階段：需求文件化 (Requirements Documentation)

### 1. 核心目標 (Core Objective)
打造一個具備**服務不中斷轉錄機制**的 AI 會議助理 MVP。此系統能從使用者本機捕獲音訊，持續進行即時轉錄與智慧潤飾，直到使用者明確停止，並支援中英雙語切換。

### 2. 第一性原理分析 (First Principles)
- **根本需求**: 使用者需要一個「可靠的數位耳朵」，能不遺漏、不間斷地捕捉對話，並將其轉化為乾淨、易讀、可用的文字記錄。核心是**持續性**與**可讀性**。
- **物理限制**:
    - **網路**: 網際網路是不穩定的。系統必須能應對短暫的斷線與延遲。
    - **瀏覽器**: 瀏覽器對背景處理、記憶體用量均有限制。
    - **模型推論**: ASR 和 LLM 推論都需要時間，這與「即時」存在本質上的矛盾。系統設計必須圍繞「管理延遲」而非「消除延遲」。

### 3. MECE 使用者情境分析 (User Scenarios)

#### 主要情境 (Happy Path):
- **情境 H-1 (開始轉錄)**: 使用者打開網頁，看到「準備就緒」狀態。點擊「開始錄製」後，系統狀態變為「正在聆聽...」，並開始捕捉本機播放的音訊（如 YouTube 影片）。
- **情境 H-2 (持續轉錄)**: 當音訊播放時，逐字稿（預設中文）持續出現在畫面上。整個過程流暢，不會因句子結束而停頓。
- **情境 H-3 (即時潤飾)**: 使用者觀察到剛出現的逐字稿會自動變化，例如「呃...那個...我想說...」在短時間內變為「我想說」。句子會被自動加上標點符號，並在適當的地方斷句。
- **情境 H-4 (雙語切換)**: 使用者點擊「切換為英文」按鈕，畫面上所有的中文逐字稿內容立刻變為對應的英文翻譯。再次點擊可切換回中文。
- **情境 H-5 (停止轉錄)**: 使用者點擊「停止錄製」，錄製圖示停止，逐字稿不再更新，系統狀態變為「錄製結束」。

#### 替代與異常情境 (Alternative & Edge Cases):
- **情境 E-1 (無聲環境)**: 使用者開始錄製，但環境安靜。系統應顯示「正在聆聽...」或「未偵測到聲音」，而非產生錯誤或無意義的輸出。
- **情境 E-2 (網路瞬斷)**: 使用者網路不穩。前端應有緩衝機制，並在 UI 上顯示「連線不穩，嘗試重連中...」的圖示。恢復連線後，應能從中斷處繼續（或僅遺失少量數據）。
- **情境 E-3 (LLM 服務延遲/失敗)**: LLM 潤飾服務回應緩慢或失敗。系統應**優雅降級**，優先顯示未經潤飾的「原始」逐字稿，確保核心轉錄功能不受影響。潤飾成功後，再更新對應的句子。
- **情境 E-4 (瀏覽器行為)**: 使用者切換到其他瀏覽器分頁。音訊捕捉與轉錄應在背景持續執行（受瀏覽器策略限制）。
- **情境 E-5 (混合語言)**: 音訊源包含中英夾雜。ASR 服務應能正確識別，並輸出包含兩種語言的逐字稿。
- **情境 E-6 (快速操作)**: 使用者在短時間內反覆點擊「開始/停止」按鈕。系統應能正確管理狀態，不會崩潰或產生非預期行為。

---

## 第二階段：功能設計 (Function Design)

根據上述需求，我們將 MVP 功能設計拆解為以下五個核心模組：

### 1. 前端音訊捕獲模組 (Client-Side Audio Capture)
- **職責**: 捕捉、處理並傳送音訊。
- **設計**:
    - 使用 **Web Audio API** (`AudioContext`) 獲取使用者麥克風或系統音訊。
    - 內建 **客戶端語音活動檢測 (VAD)**，僅在偵測到語音時，才將音訊封包（PCM a-law 格式）透過 WebSocket 傳送，以節省頻寬。
    - 管理 WebSocket 的完整生命週期狀態（Connecting, Open, Reconnecting, Closed），並在 UI 上提供明確的視覺回饋。

### 2. 即時通訊閘道模組 (Real-time Communication Gateway)
- **職責**: 作為前後端與後端微服務之間的中介。
- **設計**:
    - 使用 **FastAPI** 建立 WebSocket 端點，接收前端傳來的二進位音訊流。
    - 將音訊流非同步地轉發給 **ASR 服務**。
    - 收到 ASR 回傳的「原始片段」後，立即將其非同步地轉發給 **LLM 潤飾模組**。
    - **關鍵設計**: 為了降低延遲感，閘道會先將「原始片段」加上唯一 ID 後發送給前端。當收到「潤飾片段」後，再將其透過 ID 發送給前端進行更新。
    - 管理來自多個後端服務的回應，並統一廣播給對應的前端客戶。

### 3. ASR 轉錄服務模組 (ASR Transcription Service)
- **職責**: 專注於將音訊流轉為文字。
- **設計**:
    - 接收來自閘道的 gRPC 音訊流。
    - 核心使用 `Taiwan-Tongues-ASR-CE` 模型。
    - 輸出帶有時間戳和唯一 ID 的「原始文字片段」。

### 4. LLM 即時潤飾模組 (Live LLM Refinement)
- **職責**: 監控文字流並進行潤飾與翻譯。
- **設計**:
    - 接收閘道傳來的「原始片段」。
    - 維護一個包含上下文的短文字緩衝區（例如，最近的兩三句話）。
    - **潤飾功能**: 呼叫一個高速 LLM（例如，本地部署的 Llama-3-8B 或 Groq API）執行預設的 Prompt（例如：「請將以下文字修正得更通順自然，移除贅詞，並加上標點」）。
    - **翻譯功能**: 當使用者觸發時，呼叫 LLM 執行翻譯 Prompt。
    - 將處理完的「潤飾片段」或「翻譯片段」連同其唯一 ID 回傳給閘道。

### 5. 雙語顯示與狀態管理模組 (Bilingual Display & State)
- **職責**: 渲染與管理前端所有狀態。
- **設計**:
    - 使用 **React (Next.js)** 的狀態管理（如 Zustand 或 React Context）。
    - 資料結構：維護一個 Segments 陣列，`[{id, rawText, refinedText, translatedText, timestamp}]`。
    - UI 根據 `id` 接收並更新特定 segment 的 `refinedText` 或 `translatedText`，避免重新渲染整個列表。
    - 根據使用者選擇的語言，動態渲染 `refinedText` 或 `translatedText`。

---

## 第三階段：開發任務化 (Development Task Breakdown)

我們將採用您提出的三階段部署策略，並將開發任務拆分如下：

### 部署階段一：本機開發與驗證 - ASR 準確率與即時性驗證 (Local-Only Deployment - ASR Accuracy and Real-time Verification)

- **Sprint 0: 環境搭建**
    - **任務 (全員)**: 安裝 Docker, Node.js, Python 等本地開發環境。
    - **任務 (全端/GCP)**: 編寫 `docker-compose.yml`，整合 FastAPI, 一個模擬 ASR 的服務, 以及 Neon 的本地 Postgres 實例。
    - **任務 (AI)**: 將 `Taiwan-Tongues-ASR-CE` 模型成功容器化。

- **Sprint 1: 核心轉錄管線**
    - **任務 (全端)**: 實作前端音訊捕獲與 VAD，並建立到後端 FastAPI 的 WebSocket 連線。
    - **任務 (AI/全端)**: 將容器化的 ASR 模型整合進 docker-compose，並讓 FastAPI 能透過 gRPC 與之通訊。
    - **驗收標準**: 開發者可以在瀏覽器上點擊按鈕，終端機（後端日誌）能印出 ASR 服務回傳的「原始」中文逐字稿。

- **Sprint 2: 不中斷轉錄與 LLM 潤飾**
    - **任務 (AI)**: 使用 **Ollama** 在本地運行一個輕量級 LLM (如 Llama-3-8B)，並設計潤飾 Prompt。建立 LLM 潤飾服務。
    - **任務 (全端)**: 在閘道中整合潤飾服務，並實作「先顯示原始稿，再非同步更新潤飾稿」的機制。
    - **驗收標準**: 在前端介面上，可以看到原始逐字稿出現後，在短時間內被潤飾後的文字替換。使用長度超過 5 分鐘的 YouTube 影片進行測試，轉錄全程不中斷。

- **Sprint 3: 雙語功能與 UI**
    - **任務 (AI)**: 為 LLM 服務增加翻譯功能。
    - **任務 (全端)**: 完成前端 UI，包括語言切換按鈕、狀態顯示、美觀的逐字稿列表。
    - **驗收標準**: MVP 所有核心功能在本機環境完美運行。

### 部署階段二：類伺服器平台部署 (Staging Deployment)

- **Sprint 4: 遷移至 Railway/Cloudflare/Neon**
    - **任務 (全端/GCP)**: 將 Next.js 前端部署到 **Cloudflare Pages**。
    - **任務 (全端/GCP)**: 將 FastAPI 閘道與 LLM 潤飾服務部署到 **Railway**。
    - **任務 (全端/GCP)**: 將資料庫遷移至 **Neon** 雲端實例。
    - **挑戰與任務 (AI/GCP)**: Railway 不提供 GPU。此階段 ASR 服務有兩個選項：
        1.  **選項 A (建議)**: 暫時切換為使用第三方 ASR API（如 Deepgram/AssemblyAI）以驗證雲端管線。
        2.  **選項 B**: 在本地保留 ASR 服務，並使用 ngrok 等工具建立通道供 Railway 呼叫（僅供測試）。
    - **驗收標準**: 整個系統在公網環境下可供內部團隊測試。

### 部署階段三：GCP 生產環境部署 (Production Deployment)

- **Sprint 5: 遷移至 GCP**
    - **任務 (GCP)**: 在 **GKE** 上建立 GPU 節點池，並將容器化的 `Taiwan-Tongues-ASR-CE` 部署上去。
    - **任務 (GCP)**: 將 Railway 上的 FastAPI 與 LLM 服務遷移至 **Cloud Run** 或 GKE。
    - **任務 (全端)**: 將 Cloudflare Pages 的後端 API 指向 GCP 的負載均衡器。
    - **驗收標準**: MVP 在最終的生產環境上穩定運行，具備高可用性與擴展性。
