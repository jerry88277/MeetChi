# 專案代號 "AuditLogos"：企業級 AI 會議治理助理架構與開發藍圖研究報告

## 1. 執行摘要與戰略願景

### 1.1 專案背景與任務定義
本報告旨在為開發團隊提供一份詳盡的架構藍圖，目標是構建一個企業級的會議 AI 助理系統。作為開發團隊的管理者，我們面臨的挑戰不僅是技術實作，更是一場關於「資訊治理」的數位轉型。根據需求，我們的團隊編制涵蓋了 AI 演算法工程師、資訊安全工程師以及 **Google Cloud Platform (GCP)** 部署工程師，這意味著我們必須從模型效能、系統安全與基礎建設彈性三個維度來審視整個專案。

本次開發的核心任務包含三大功能支柱：
1.  具備 **LLM** 潤飾能力的即時語音轉錄（MVP 核心）。
2.  基於提示詞模板的結構化會議記錄生成。
3.  支援多媒體上傳與多格式匯出的非同步處理能力。

值得注意的是，技術選型上已明確指定採用 **adi-gov-tw/Taiwan-Tongues-ASR-CE** 作為語音識別引擎，並部署於 **GCP** 環境。這項決策確立了我們在台灣在地化語言處理上的優勢，特別是針對中英夾雜與台語混用的商務場景，但也同時帶來了模型部署與推論延遲的技術挑戰。

### 1.2 從轉錄到決策：市場典範轉移
根據《Meeting Ink 白皮書：AI 會議紀錄從文字轉錄到決策》的市場調查數據顯示，當前企業對於會議工具的需求已發生根本性的質變[^1]。過去市場競逐的是「逐字稿的準確率」（Word Error Rate, WER），但現在戰場已轉移至「決策速度」（Decision Velocity）。企業觀點認為，摘要與模板本質上是將 AI 能力封裝成「可治理的工作標準」[^1]。這意味著我們的 AI 助理不能僅僅是一個被動的速記員，而必須進化為一個主動的「會議顧問」。

數據顯示，約有 40% 的會議在結束後會產出摘要，這代表使用者已將 AI 工具視為生產力流程的一部分，而非單純的錄音倉庫[^1]。因此，本專案的戰略核心在於「結構化認知」——即如何透過精心設計的**提示工程（Prompt Engineering）**，將非結構化的對話流轉化為結構化的決策數據（如：待辦事項、風險評估、決策結論），並確保這些數據具備可追溯性與可稽核性。

### 1.3 方法論：第一性原理與 MECE 分析
為了確保系統架構的堅韌性，本報告將採用**「第一性原理」（First Principles）**與**「MECE」（Mutually Exclusive, Collectively Exhaustive，相互獨立、完全窮盡）**原則進行分析。我們將解構現有的開源專案（如 TranscriptHub, meeting-minutes 等），剝離其表層功能，直探其運作的物理本質（如音訊流的封包處理、上下文視窗的限制、瀏覽器記憶體管理），再根據我們的特定需求（**GCP** 架構、台灣語言模型）進行重構。這將確保我們的設計不僅僅是功能的堆疊，而是從底層邏輯上就具備高效能與高擴展性。

## 2. 第一性原理視角下的開源生態解構與重構
為了避免重複造輪子並吸取社群的最佳實踐，我們針對六個關鍵 GitHub 專案進行深度剖析。我們不關注其程式碼細節，而是關注其解決問題的「核心真理」。

### 2.1 AS-AIGC/TranscriptHub：聚合層的物理本質
- **第一性原理分析**：TranscriptHub 的存在解決了「模型碎片化」的問題。其核心真理在於，使用者不關心背後是 **OpenAI** 還是 **Azure**，他們只關心「輸入音訊，輸出文字」。從系統設計角度看，這是一個標準的**「適配器模式」（Adapter Pattern）**應用，將異質的 API 介面標準化。
- **MECE 解構**：
    - **輸入端**：涵蓋即時流（**WebSocket**）與靜態檔（Upload）。
    - **處理端**：涵蓋同步請求與非同步隊列。
    - **輸出端**：涵蓋原始 JSON 與格式化文本（SRT/VTT）。
- **本專案重構策略**：雖然我們鎖定 **adi-gov-tw** 模型，但為了系統的**強韌性（Robustness）**，GCP 部署工程師需設計一個「模型抽象層」。這允許我們在模型負載過高或遇到極端方言障礙時，能動態切換至備援模型（如 Google Speech-to-Text API），確保服務不中斷。

### 2.2 Zackriya-Solutions/meeting-minutes：認知壓縮的邏輯
- **第一性原理分析**：此專案的核心在於「資訊熵的減少」。原始逐字稿包含大量冗餘資訊，其價值密度極低。該專案透過 **LLM** 的語意理解能力，將高熵的對話壓縮為低熵的摘要。
- **MECE 解構**：
    - **切分策略（Chunking）**：處理超長會議（超過 LLM Context Window）的物理限制，通常採用 **Map-Reduce** 或 **Refine** 策略。
    - **提示策略（Prompting）**：分為**零樣本（Zero-shot）**與**少樣本（Few-shot）**學習，決定了輸出的結構化程度。
- **本專案重構策略**：我們將引入 MeetingInk 提出的「模板治理」概念[^1]。AI 工程師需設計一套動態的 **Chunking** 機制，不僅是按時間切分，更要按「語者轉換」或「主題變更」進行語意切分，以提高摘要的精準度。

### 2.3 WEIFENG2333/VideoCaptioner：多媒體處理的管線物理
- **第一性原理分析**：影片轉錄本質上是「訊號分離」與「時間對齊」的過程。視覺訊號（Video）與聽覺訊號（Audio）必須被**解耦合（Demuxing）**，處理完畢後再重新**耦合（Remuxing）**。
- **MECE 解構**：
    - **前處理**：格式轉換（ffmpeg）、採樣率統一（16kHz 為 ASR 標準）。
    - **對齊**：時間戳記（Timestamp）的精確映射。
- **本專案重構策略**：這直接對應到我們的「功能 3」。GCP 部署工程師需利用 **Cloud Functions** 與 **Cloud Storage** 構建一個事件驅動的媒體處理管線。當大檔案上傳時，不應阻塞主伺服器，而是觸發一個獨立的運算單元（**Cloud Run Jobs**）進行 ffmpeg 處理，確保系統的高吞吐量。

### 2.4 QuentinFuxa/WhisperLiveKit：即時流的時序挑戰
- **第一性原理分析**：即時轉錄（**Real-time ASR**）與離線轉錄截然不同，它處理的是「無限長的二進位流」。其核心挑戰在於「延遲」與「準確度」的博弈。串流需要持續的 **WebSocket** 連線狀態管理。
- **MECE 解構**：
    - **傳輸層**：**WebSocket** vs **gRPC**。
    - **切分邏輯**：**語音活動檢測（VAD）**決定何時將緩衝區送入模型。
- **本專案重構策略**：這是 MVP 的核心。我們必須實作「客戶端 VAD」。資安工程師需注意，**WebSocket** 連線長時間保持開啟可能帶來的 **DDoS** 風險，需配置 **Cloud Armor** 進行流量清洗。同時，AI 工程師需在後端實作「推測性解碼」或「穩定性演算法」，解決即時字幕閃爍（Flickering）的問題。

### 2.5 misbahsy/meetingmind：全端互動的體驗設計
- **第一性原理分析**：使用者的價值感知並非來自後端強大的模型，而是來自前端的「互動儀表板」。MeetingMind 展現了 **React/Next.js** 在狀態管理上的優勢，將會議記錄視為一個可檢索的資料庫。
- **MECE 解構**：
    - **狀態同步**：錄音中的波形視覺化與文字生成的同步渲染。
    - **資料持久化**：會議結束後的資料庫寫入與索引建立。
- **本專案重構策略**：參考 MeetingInk 的發現，使用者需要的是「可交付的成果」[^1]。前端設計不應只是一個播放器，而應是一個「編輯器」。我們需在 **Next.js** 中實作富文本編輯器，讓使用者能即時修正 AI 的錯誤，並將修正回饋給模型（**Human-in-the-loop**）。

### 2.6 superlanding/x-meet：瀏覽器整合的邊界突破
- **第一性原理分析**：會議發生在瀏覽器分頁中（Google Meet/Teams），而非桌面應用。x-meet 利用**瀏覽器擴充功能（Extension）**突破了作業系統的音訊捕獲限制。
- **MECE 解構**：
    - **音訊源捕獲**：`chrome.tabCapture` API 與系統麥克風的混音（Mixing）。
    - **介面注入**：將字幕層覆蓋（Overlay）在會議軟體之上。
- **本專案重構策略**：雖然初期可能以獨立 Web App 為主，但長遠規劃必須包含瀏覽器擴充功能。這能讓我們的產品無縫嵌入使用者的工作流，直接在 Google Meet 介面中顯示即時字幕與 AI 摘要。

### 2.7 fastrepl/hyprnote：邊緣運算的隱私邊界
- **第一性原理分析**：`hyprnote` 的核心真理是**「資料主權」**與**「隱私保護」**。它將 AI 計算帶到資料端（即使用者本機），而非將資料送到雲端。透過監聽系統音訊並在本地處理，它從根本上消除了對會議內容外洩的擔憂，這對於處理高度敏感資訊的企業或個人具有無可取代的價值。
- **MECE 解構**：
    - **應用程式層**：使用 **Tauri** (Rust + React) 框架，兼顧了執行的效能與前端開發的效率。
    - **儲存層**：**本地優先（Local-first）**架構，所有筆記和逐字稿預設儲存在使用者本機，可能採用 SQLite。
    - **AI 模型層**：**可插拔設計（Pluggable）**。支援完全離線的本地 LLM（如 **Ollama**, **LM Studio**），同時也提供選項連接到雲端 LLM API（如 Gemini, Claude）。
    - **整合層**：支援與 Apple Calendar, Obsidian 等本地應用程式整合，強化個人工作流程。
- **本專案重構策略**：
    1.  **強化模型服務的彈性**：`hyprnote` 的可插拔 LLM 策略是重要的啟示。我們的 **LLM Service** 必須設計成一個具有標準化介面的「路由器」，使其能輕易地在不同的 LLM 提供者之間切換。這不僅包括雲端 API，也應預留連接到本地（或企業私有雲）Ollama 服務的選項，以滿足不同客戶的資安等級和成本考量。
    2.  **使用者為中心的摘要**：其「基於使用者筆記生成個人化摘要」的功能點，為我們的摘要演算法提供了新思路。我們的 **CrewAI** 分析師 Agent 不應只對完整逐字稿進行無差別摘要，而應優先分析使用者在會議中標記的「重點」（Timestamp Markers），並結合這些重點來生成更貼近使用者需求的摘要。
    3.  **探索混合架構**：雖然我們的專案是雲端優先，但 `hyprnote` 的成功驗證了市場對本地化、高隱私方案的需求。在產品的未來藍圖中，可以規劃一個「企業內部部署 (On-Premise)」版本或一個功能有限的「離線版」桌面應用，作為產品線的延伸。

## 3. 廣泛調查階段：技術堆疊評估與可行性分析
在此階段，我們深入評估指定的技術堆疊：**CrewAI + Next.js + Python**，並結合 **GCP** 架構進行可行性驗證。

### 3.1 CrewAI + Next.js + Python 實作可行性評估

#### 3.1.1 Next.js (Frontend)
- **評估結論**：極高度推薦。
- **技術依據**：**Next.js** (基於 React) 是目前建構高效能儀表板的業界標準。其 **Server-Side Rendering (SSR)** 與 **React Server Components (RSC)** 特性能夠有效處理大量會議歷史列表的渲染效能。
- **即時性挑戰**：對於功能 1（即時轉錄），**Next.js** 需要透過 Custom Hooks (`useWebSocket`) 來管理 **WebSocket** 連線。需特別注意**記憶體洩漏（Memory Leak）**問題，會議可能長達數小時，前端若未妥善管理 DOM 節點增長，會導致瀏覽器崩潰。

#### 3.1.2 Python (Backend)
- **評估結論**：必要且唯一選擇。
- **技術依據**：AI 生態系（**PyTorch**, **HuggingFace**, **LangChain**）原生支援 **Python**。**adi-gov-tw** 模型本身即是以 **Python** 運行。
- **架構建議**：採用 **FastAPI** 作為後端框架。相較於 Flask/Django，**FastAPI** 原生支援非同步處理 (`async/await`)，這對於處理大量並發的 **WebSocket** 連線（即時字幕服務）至關重要。同步框架在高並發下會導致**線程阻塞（Thread Blocking）**，無法滿足即時性需求。

#### 3.1.3 CrewAI (Agentic Orchestration)
- **評估結論**：適用於後處理（功能 2），不適用於即時處理（功能 1）。
- **技術依據**：**CrewAI** 是一個多代理人（Multi-Agent）協作框架，擅長複雜的任務規劃與執行。
- **應用場景**：
    - **即時轉錄**：不建議使用。**CrewAI** 的代理人互動涉及多次 **LLM** 往返，延遲極高，無法滿足即時字幕「毫秒級」的要求。
    - **結構化會議記錄**：完美契合。我們可以設計一個「虛擬秘書團隊」：
        - **Agent A (記錄員)**：負責清理逐字稿，修正錯別字。
        - **Agent B (分析師)**：根據選定的模板（如 BANT 銷售模板[^1]）提取關鍵資訊。
        - **Agent C (稽核員)**：檢查是否有遺漏的欄位（如「待辦事項」未指定負責人），落實 MeetingInk 提到的治理需求[^1]。

### 3.2 meetingmind 與 x-meet 前端資訊的深度洞察
根據 `prompt.md` 中對於這些專案的描述（模擬），我們歸納出以下前端設計規範：
- **視覺化回饋**：即時錄音介面必須包含**音波圖（Waveform）**，這不僅是美觀，更是讓使用者確認「麥克風有在收音」的重要 UX 指標。
- **滾動鎖定機制**：當即時字幕快速生成時，視窗會自動捲動到底部。但若使用者想回看前一段話，系統必須偵測到滾動行為並暫停自動捲動（Scroll Lock），否則使用者體驗會極差。
- **標籤管理系統**：`meetingmind` 顯示了**標籤（Tags）**的重要性。我們的前端需支援在錄音過程中**「打點」（Timestamp Marker）**，例如點擊「重要」按鈕，便在當下時間戳記上標記，供後續 **CrewAI** 優先處理該段落。

## 4. 核心技術深探：adi-gov-tw 模型與 GCP 架構
本專案的心臟是 **adi-gov-tw/Taiwan-Tongues-ASR-CE** 模型。要駕馭此模型，我們必須深入了解其特性與部署眉角。

### 4.1 模型特性推論與在地化優勢
雖然我們將其視為黑盒，但根據命名與用途推斷，此模型極可能基於 **Conformer** 或 **Whisper** 架構進行了針對台灣口音、台語（Hokkien）與**中英夾雜（Code-switching）**的**微調（Fine-tuning）**。
- **Code-Switching 挑戰**：台灣商務會議常出現「這個 Project 的 Schedule 有點 delay」這類語句。標準的中文或英文模型常會在此崩潰。此模型的價值在於能平滑處理語種切換。
- **台語支援**：針對政府或傳統產業會議，台語識別是剛需。
- **推論成本**：這類大模型通常參數量巨大（可能在 1B 以上），對 VRAM 有較高要求。

### 4.2 GCP 部署架構設計（資安與效能並重）
GCP 部署工程師需構建以下基礎設施：

| 元件層級 | GCP 服務 | 選型理由 |
| :--- | :--- | :--- |
| **運算層 (ASR)** | **GKE** (Google Kubernetes Engine) | 需配置 GPU Node Pool (NVIDIA L4 或 T4)。GKE 提供容器編排能力，能根據 CPU/GPU 利用率自動擴縮（Auto-scaling），應對會議尖峰。 |
| **運算層 (Backend)** | **Cloud Run** | 用於 FastAPI 服務與 CrewAI 代理人。Serverless 架構，依請求計費，適合處理 HTTP API 與 WebHook。 |
| **儲存層 (Raw)** | **Cloud Storage (GCS)** | 儲存原始音訊/影片檔。需設定 Lifecycle Policy，將超過 30 天的檔案轉入 Coldline 以節省成本[^1]。 |
| **資料庫 (Meta)** | **Cloud SQL (PostgreSQL)** | 儲存使用者資料、會議元數據、權限設定。 |
| **資料庫 (Vector)** | **Vertex AI Vector Search** | 儲存逐字稿的向量嵌入（Embeddings），支援語意搜尋功能（如：「搜尋關於預算的所有討論」）。 |
| **網路層** | **Cloud Load Balancing** | 支援 WebSocket 協議，並開啟 Session Affinity（黏性會話），確保串流封包路由到同一台 ASR 伺服器。 |
| **安全層** | **VPC Service Controls & IAM** | 資安工程師需設定 VPC 邊界，限制資料僅能在特定專案內流動。IAM 權限需遵循最小權限原則（Least Privilege）。 |

## 5. 需求訪談與使用者畫像分析（基於 MeetingInk 白皮書）
根據 MeetingInk 白皮書的研究，我們不能將所有使用者視為同一類人。不同的職位對「會議記錄」有完全不同的期待[^1]。

### 5.1 銷售代表 (Sales Rep)
- **痛點**：每天與多個客戶通話，常忘記客戶的具體反對意見（Objection）或預算細節。
- **需求**：
    - **模板**：**BANT** (Budget, Authority, Need, Timing)。
    - **功能**：通話結束後 5 分鐘內，自動生成一封「後續跟進 Email」草稿，包含雙方達成共識的下一步。
- **治理重點**：確保摘要內容準確，避免承諾未經授權的折扣。

### 5.2 人資經理 (HR Manager)
- **痛點**：面試紀錄散落在紙本筆記，難以進行公平的跨候選人比較；且需避免紀錄中出現帶有偏見的詞彙。
- **需求**：
    - **模板**：**STAR** (Situation, Task, Action, Result) 或勝任力評分表。
    - **功能**：敏感資料保護。面試錄音需在生成摘要後自動進行 **PII（個人識別資訊）**去識別化，且錄音檔需設定嚴格的存取權限。
- **治理重點**：**合規性（ISO 27001/GDPR）**，確保面試流程符合公司政策[^1]。

### 5.3 研發主管 (R&D Lead)
- **痛點**：技術會議冗長，決策常淹沒在技術細節討論中。
- **需求**：
    - **模板**：決策/風險/障礙 (**Decision/Risk/Blocker**)。
    - **功能**：與 **Jira/Linear** 整合。AI 識別出的「Action Item」應能一鍵轉換為 Jira Ticket。
- **治理重點**：**可追溯性**。三個月後若程式碼出問題，能回溯當初是「誰」在「什麼情境」下做出的架構決策。

## 6. 功能模組設計與實作藍圖
我們將系統劃分為三個核心模組，並依照優先順序進行開發。

### 6.1 模組一：即時字幕串流引擎 (MVP 核心)
這是最技術密集且最優先的模組。
- **客戶端 (Next.js)**：
    - 利用 **Web Audio API** (`AudioContext`) 擷取麥克風串流。
    - **邊緣運算 VAD**：在瀏覽器端載入輕量級 VAD 模型（如 `onnx-silero-vad`）。只有偵測到人聲時才發送 WebSocket 封包，這能節省 50% 以上的伺服器頻寬與 GPU 運算資源。
- **伺服器端 (FastAPI + GKE)**：
    - **串流緩衝區 (Buffer)**：接收二進位音訊流，組合成適合模型推論的長度（例如 0.5 秒）。
    - **推論優化**：利用 **NVIDIA Triton Inference Server** 部署 Taiwan-Tongues 模型，並開啟 **Dynamic Batching**，同時處理多個使用者的請求。
    - **LLM 潤飾 (非同步)**：當 ASR 輸出一個完整句子後，將其推送到一個輕量級 LLM（如 Llama-3-8B，部署於同叢集），進行即時語法修正（去除冗詞、修正倒裝句），然後再推送到前端顯示。

### 6.2 模組二：結構化會議記錄生成器 (MeetingInk 引擎)
這是展現商業價值的模組，落實「模板即治理」的概念。
- **觸發機制**：會議結束或檔案上傳完成。
- **CrewAI 協作流**：
    1.  **步驟 1 (Map)**：若會議超過 1 小時，先將逐字稿切分為 10 分鐘的片段，由 `Summarizer Agent` 進行摘要。
    2.  **步驟 2 (Reduce)**：將所有片段摘要合併。
    3.  **步驟 3 (Extract)**：`Extractor Agent` 載入使用者選定的模板（如「專案週會」），從合併摘要中提取特定欄位（如「進度落後項目」）。
    4.  **步驟 4 (Verify)**：`Governance Agent` 檢查輸出品質。例如，若發現有「待辦事項」但沒有「負責人」或「截止日」，則標記為「缺失」，並在前端提示使用者手動補充。

### 6.3 模組三：多媒體中心與匯出
- **媒體處理管線**：
    - 使用者上傳影片 -> GCS Bucket -> 觸發 Cloud Pub/Sub -> 啟動 Cloud Run Job。
    - Job 執行 `ffmpeg` 提取音軌 -> 呼叫 ASR 服務 -> 儲存結果。
- **多格式匯出**：
    - **PDF/Docx**：用於正式公文。需包含會議資訊表頭、結構化摘要、以及完整的逐字稿附錄。
    - **SRT/VTT**：用於影片字幕。需精確對應時間軸。
    - **JSON**：用於系統整合（如匯入 Notion）。

## 7. 專案實施路線圖 (Roadmap)

### 第一階段：基礎建設與 MVP (第 1-4 週)
- **目標**：完成 GCP 環境搭建，並實現「對著瀏覽器說話，看到字幕出現」。
- **關鍵產出**：
    - GKE GPU Cluster 就緒。
    - Taiwan-Tongues 模型成功容器化並透過 WebSocket 服務。
    - Next.js 前端具備基本的錄音與即時顯示功能。
- **驗收標準**：即時字幕延遲 < 3 秒，中英夾雜識別率可接受。

### 第二階段：結構化智慧 (第 5-8 週)
- **目標**：整合 CrewAI 與模板系統。
- **關鍵產出**：
    - 實作 Sales, HR, R&D 三大基礎模板。
    - 完成後端非同步任務隊列（Celery/Redis）。
    - 前端儀表板支援會議歷史瀏覽與摘要編輯。
- **驗收標準**：MeetingInk 的 `SCR (Summary Creation Rate)` 指標追蹤機制上線。

### 第三階段：企業級交付 (第 9-12 週)
- **目標**：資安合規、檔案上傳與匯出。
- **關鍵產出**：
    - 實作 IAM 角色權限管理。
    - 完成 PII 自動遮罩功能。
    - 支援影片上傳與 PDF 匯出。
- **驗收標準**：通過資安工程師的滲透測試與 ISO 合規性檢查。

## 8. 結論
本專案不僅僅是導入一個語音識別模型，而是為企業構建一套「聽覺神經系統」。透過採用 **adi-gov-tw/Taiwan-Tongues-ASR-CE**，我們確保了系統在台灣語言環境下的適應性；透過 **CrewAI** 與結構化模板的結合，我們落實了 MeetingInk 所倡議的「資訊治理」，將會議噪音轉化為高價值的決策資產。憑藉 **GCP** 強大的基礎設施與我們嚴謹的**第一性原理**架構設計，團隊已準備好迎接開發挑戰，將此 AI 助理打造為提升企業決策速度的關鍵引擎。

---
## 參考文獻
[^1]: MeetingInk白皮書.pdf
